{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb06f5-57bb-4df8-9fca-7d80c0dc0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai pymupdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cce11c-d688-4f54-be46-570315a548ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üîê Load Your OpenAI API Key\n",
    "\n",
    "- üìÑ Loads the `.env` file containing your **OpenAI API key**  \n",
    "- üß† You must already have a key from [platform.openai.com](https://platform.openai.com)  \n",
    "- üë§ Log in ‚Üí Profile ‚Üí **View API Keys** ‚Üí Create & copy your **secret key**  \n",
    "- üíæ Store it securely in a `.env` file on your computer (e.g., `OPENAI_API_KEY=your_key_here`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f364f5e-904d-4d97-a849-4c36ba827a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb98e1-5fd4-4e8c-b5e4-eced5ad76e80",
   "metadata": {},
   "source": [
    "üìå **Load required libraries and set up the OpenAI API key.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e6ba1-a88d-4723-8b10-ea006bfa5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import time\n",
    "\n",
    "dotenv_path = Path(\"D:/Python/Samples_VS/pythonLearning/OpenAI_key.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888cf9a-369c-4c10-9bbc-2429d908d2ce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "### ‚öôÔ∏è Setup & Logic\n",
    "\n",
    "- üì• Sets input PDF path (word list) and üì§ output folder for stories  \n",
    "- üìÑ Extracts text from each page and ‚úÇ filters short, relevant words  \n",
    "- ü§ñ Uses OpenAI API to generate C1-level stories in simple German  \n",
    "- üßë‚Äçüè´ Applies inductive learning: compound breakdowns & synonyms  \n",
    "- üíæ Saves each story as a text file by page and story number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2fb79-0e9c-4430-9881-62897b13d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "pdf_path = r\"D:\\Python\\Samples_VS\\pythonLearning\\C1_german\\wortschatz.pdf\"\n",
    "output_dir = r\"D:\\Python\\Samples_VS\\pythonLearning\\C1_german\\generated_texts\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# === FUNCTION: Extract text from a page ===\n",
    "def extract_text_from_page(pdf_doc, page_number):\n",
    "    page = pdf_doc.load_page(page_number)\n",
    "    return page.get_text()\n",
    "\n",
    "# === FUNCTION: Extract words from a page (basic split) ===\n",
    "def extract_words_from_text(text):\n",
    "    lines = text.splitlines()\n",
    "    words = [\n",
    "        line.strip()\n",
    "        for line in lines[0:-4]\n",
    "        if line.strip() and len(line.strip()) < 40 and ' S. ' not in line\n",
    "    ]\n",
    "    return words\n",
    "\n",
    "\n",
    "# === FUNCTION: Ask GPT for a story ===\n",
    "def ask_gpt_for_story(page_num, story_num, words, text_style):\n",
    "    word_list = \", \".join(words)\n",
    "    prompt = f\"\"\"\n",
    "Imagine that you are a teacher of German who wants adult learners to learn German advanced words, C1 level,\n",
    "using inductive language acquisition. Write me a pedogogical and engagig {text_style} (around 400 words) \n",
    "in simple German, in which you use these words:\n",
    "\n",
    "{word_list}. The point is that the reader learns these new words passively as he reads the text.\n",
    "\n",
    "Before the text, list the words under \"Neue W√∂rter in diesem Text:\" with the equevalent English word in parenthesis.\n",
    "Inside the text, \n",
    "Importantly, make the meaning of each word easy to guess, using techniques like:\n",
    "‚Äì breaking compound words to the elements, and taking advantage of ethymological similarity with English, e.g., Er war Rast.los (rest.less),\n",
    "- breakoing down coumpund words and make the meaning clearer: beschleunigung --> be.schenell.igung\n",
    "‚Äì using examples or oter German synonyms right after a word between commas.\n",
    "‚Äì if the word is hard to be guessed, like abstract concepts, then adding English equivalents in parentheses is \n",
    "also absolutely ok.\n",
    "try to write the text in a way that apart from the 'new words', other expressions would be easy to understand.\n",
    "The goal is not the perfect text or story, but language learning. Avoid complicated grammar. Use the words naturally, \n",
    "but clearly. prevent from using phrases, like, it means, ... , or this word means, ..., just say what it means, \n",
    "especially with examples or synonyms. In the text, when a 'new word' from the list is used, print it in bold.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        story = response.choices[0].message.content.strip()\n",
    "        filename = os.path.join(output_dir, f\"{page_num+1}_{story_num+1}_text.txt\")\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(story)\n",
    "        print(f\"‚úî Saved story to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error on page {page_num+1}, story {story_num+1}: {e}\")\n",
    "        time.sleep(5)  # Wait a bit before retrying or moving on\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c37115-283e-4d6b-b5d7-6bee89d1fabf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### üîÅ Main Loop ‚Äì Process & Generate\n",
    "\n",
    "- üìÑ Loops through each page of the PDF  \n",
    "- ‚úÇ Extracts and saves filtered word lists  \n",
    "- üé≤ Generates 10 short texts per page with random word subsets  \n",
    "- üó£ Text style is randomly chosen: dialogue, story, or report  \n",
    "- ü§ñ Uses OpenAI API to generate pedagogical C1-level stories  \n",
    "- üïí Waits between requests to avoid rate limits  \n",
    "- ‚úÖ Closes the PDF and prints when finished\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4399b-1e68-4b27-b00f-4ce16daae011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MAIN LOOP ===\n",
    "def main():\n",
    "    pdf_doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(len(pdf_doc)):\n",
    "        print(f\"üìÑ Processing page {page_num+1}\")\n",
    "        text = extract_text_from_page(pdf_doc, page_num)\n",
    "        words = extract_words_from_text(text)\n",
    "\n",
    "        if not words:\n",
    "            print(f\"‚ö† No words found on page {page_num+1}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Save extracted words to file\n",
    "        word_file = os.path.join(output_dir, f\"{page_num+1}_words.txt\")\n",
    "        with open(word_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(words))\n",
    "        print(f\"üìÅ Saved words to {word_file}\")\n",
    "\n",
    "\n",
    "        # Define the possible styles\n",
    "        styles = [    \"realistic dialogue\", \"creative fictional or realistic story\",\n",
    "             \"non-fiction documentation-style report\"\n",
    "        ]\n",
    "        # Generate 10 stories with random subsets of words\n",
    "        for story_num in range(10):\n",
    "            subset_size = min(len(words), 15)\n",
    "            selected_words = random.sample(words, subset_size)\n",
    "            # Randomly choose a style (with equal weights)\n",
    "            style_instruction = random.choice(styles)\n",
    "            ask_gpt_for_story(page_num, story_num, selected_words, style_instruction)\n",
    "            time.sleep(5)  # To avoid hitting rate limits\n",
    "\n",
    "    \n",
    "    pdf_doc.close()\n",
    "    print(\"‚úÖ All done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
